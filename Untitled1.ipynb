{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pdb\n",
    "import csv\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "\tdef __init__(self, csv_path):\n",
    "\t\tself.points = 0.00001\n",
    "\t\tself.spread_points = 5\n",
    "\t\tself.tp_points = 500\n",
    "\t\tself.sl_points = 500\n",
    "\n",
    "\t\tself.dataset = []\n",
    "\t\tself.next_index = 0;\n",
    "\n",
    "\t\twith open(csv_path, newline='') as csvfile:\n",
    "\t\t\treader = csv.reader(csvfile, delimiter=';')\n",
    "\t\t\tfor row in reader:\n",
    "\t\t\t\tdate, hour, \\\n",
    "\t\t\t\top, high, low, close, \\\n",
    "\t\t\t\ttick_vol, vol, spread = row\n",
    "\t\t\t\t\n",
    "\t\t\t\tentry = {\n",
    "\t\t\t\t\t'date': date,\n",
    "\t\t\t\t\t'hour': hour,\n",
    "\t\t\t\t\t'tick_vol': float(tick_vol),\n",
    "\t\t\t\t\t'vol': float(vol),\n",
    "\t\t\t\t\t'open': float(op),\n",
    "\t\t\t\t\t'close': float(close),\n",
    "\t\t\t\t\t'high': float(high),\n",
    "\t\t\t\t\t'low': float(low),\n",
    "\t\t\t\t}\n",
    "\t\t\t\tself.dataset.append(entry)\n",
    "\n",
    "\t\tself.input_size = len(self.__build_state(0)[0])\n",
    "\t\tself.action_space = [0, 1, 2] # 0: pass, 1: long, 2: short\n",
    "\n",
    "\tdef report(self):\n",
    "\t\treturn \"Long Trades: {} ({} won), Short Trades: {} ({} won), won %: {}, profit: {} (gross gain: {}, gross loss: {})\".format(\n",
    "\t\t\tself.long_trades, self.long_trades_won, self.short_trades, self.short_trades_won,\n",
    "\t\t\t(self.long_trades_won + self.short_trades_won) / (self.long_trades + self.short_trades),\n",
    "\t\t\tround(self.gross_profit + self.gross_loss), round(self.gross_profit), round(self.gross_loss)\n",
    "\t\t)\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.next_index = 0\n",
    "\t\tself.short_trades = 0\n",
    "\t\tself.long_trades = 0\n",
    "\t\tself.long_trades_won = 0\n",
    "\t\tself.short_trades_won = 0\n",
    "\t\tself.short_trades_lost = 0\n",
    "\t\tself.gross_profit = 0\n",
    "\t\tself.gross_loss = 0\n",
    "\n",
    "\t\treturn self.step(self.action_space[0])[0]\n",
    "\n",
    "\tdef step(self, action):\n",
    "\t\treward, nindex = self.__calculate_reward(action, self.next_index)\n",
    "\n",
    "\t\tdistance = max(1, nindex - self.next_index)\n",
    "\t\tself.next_index = nindex\n",
    "\t\tnext_state, has_next_state = self.__build_state(self.next_index)\n",
    "\n",
    "\t\tdone = False\n",
    "\t\tif not has_next_state: done = True\n",
    "\n",
    "\t\treturn (next_state, reward / distance, done)\n",
    "\n",
    "\tdef __build_state(self, index):\n",
    "\t\tif index >= len(self.dataset):\n",
    "\t\t\treturn (None, False)\n",
    "\n",
    "\t\trow = self.dataset[index]\n",
    "\t\thour = tf.keras.utils.to_categorical(row['hour'].split(':')[0], 24)\n",
    "\t\t\n",
    "\t\tstate = []\n",
    "\n",
    "\t\tfor i in range(index,index-48,-1):\n",
    "\t\t\tif not self.dataset[i]:\n",
    "\t\t\t\tstate.append(self.dataset[i]['close'])\n",
    "\t\t\telse:\n",
    "\t\t\t\tstate.append(row['close'])\n",
    "\n",
    "\t\treturn (np.concatenate((hour, state)), True)\n",
    "\t\t# return (state, True)\n",
    "\n",
    "\tdef __calculate_reward(self, action, index):\n",
    "\t\tif action == 0: # pass\n",
    "\t\t\treward = -1\n",
    "\t\t\tnindex = index + 1\n",
    "\t\tif action == 1: # long\n",
    "\t\t\treward, nindex = self.__calculate_position_reward(True, index)\n",
    "\t\t\tself.long_trades += 1\n",
    "\n",
    "\t\t\tif reward > 0: self.long_trades_won += 1\n",
    "\t\t\tself.gross_profit += max(0, reward)\n",
    "\t\t\tself.gross_loss += min(0, reward)\n",
    "\t\tif action == 2: # short\n",
    "\t\t\treward, nindex = self.__calculate_position_reward(False, index)\n",
    "\t\t\tself.short_trades += 1\n",
    "\n",
    "\t\t\tif reward > 0: self.short_trades_won += 1\n",
    "\t\t\tself.gross_profit += max(0, reward)\n",
    "\t\t\tself.gross_loss += min(0, reward)\n",
    "\t\t\n",
    "\n",
    "\t\treturn (reward, nindex)\n",
    "\n",
    "\n",
    "\tdef __calculate_position_reward(self, long, index):\n",
    "\t\topen_bid, open_ask = \\\n",
    "\t\t\t(\n",
    "\t\t\t\tself.dataset[index]['close'] - self.__points(self.spread_points) / 2,\n",
    "\t\t\t\tself.dataset[index]['close'] + self.__points(self.spread_points) / 2\n",
    "\t\t\t)\n",
    "\t\t\n",
    "\t\topen_price = open_ask if long else open_bid\n",
    "\t\tif long:\n",
    "\t\t\topen_position_tp_price = open_bid + self.__points(self.tp_points) + self.__points(self.spread_points)\n",
    "\t\t\topen_position_sl_price = open_bid - self.__points(self.sl_points) + self.__points(self.spread_points)\n",
    "\t\telse:\n",
    "\t\t\topen_position_tp_price = open_ask - self.__points(self.tp_points) - self.__points(self.spread_points)\n",
    "\t\t\topen_position_sl_price = open_ask + self.__points(self.sl_points) - self.__points(self.spread_points)\n",
    "\n",
    "\t\tindex += 1\n",
    "\t\twhile index < len(self.dataset):\n",
    "\t\t\tif long:\n",
    "\t\t\t\thigh_bid = self.dataset[index]['high'] - self.__points(self.spread_points) / 2\n",
    "\t\t\t\tlow_bid = self.dataset[index]['low'] - self.__points(self.spread_points) / 2\n",
    "\n",
    "\t\t\t\tif low_bid <= open_position_sl_price:\n",
    "\t\t\t\t\t# print(\"LONG SL ({}):  From {} to {} ({})\".format(index, open_price, open_position_sl_price, round((open_position_sl_price - open_price) / self.points)))\n",
    "\t\t\t\t\treturn ((open_position_sl_price - open_price) / self.points, index + 1)\n",
    "\t\t\t\tif high_bid >= open_position_tp_price:\n",
    "\t\t\t\t\t# print(\"LONG TP ({}):  From {} to {} ({})\".format(index, open_price, open_position_tp_price, round((open_position_tp_price - open_price) / self.points)))\n",
    "\t\t\t\t\treturn ((open_position_tp_price - open_price) / self.points, index + 1)\n",
    "\t\t\telse:\n",
    "\t\t\t\thigh_ask = self.dataset[index]['high'] + self.__points(self.spread_points) / 2\n",
    "\t\t\t\tlow_ask = self.dataset[index]['low'] + self.__points(self.spread_points) / 2\n",
    "\n",
    "\t\t\t\tif high_ask >= open_position_sl_price:\n",
    "\t\t\t\t\t# print(\"SHORT SL ({}): From {} to {} ({})\".format(index, open_price, open_position_sl_price, round((open_price - open_position_sl_price) / self.points)))\n",
    "\t\t\t\t\treturn ((open_price - open_position_sl_price) / self.points, index + 1)\n",
    "\t\t\t\tif low_ask <= open_position_tp_price:\n",
    "\t\t\t\t\t# print(\"SHORT TP ({}): From {} to {} ({})\".format(index, open_price, open_position_tp_price, round((open_price - open_position_tp_price) / self.points)))\n",
    "\t\t\t\t\treturn ((open_price - open_position_tp_price) / self.points, index + 1)\n",
    "\n",
    "\t\t\tindex += 1\n",
    "\n",
    "\t\t# if I'm here, it's end of the dataset\n",
    "\t\treturn (0, index)\n",
    "\n",
    "\n",
    "\tdef __points(self, val):\n",
    "\t\treturn val * 0.00001\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                2336      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 4,547\n",
      "Trainable params: 4,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training (1):\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 2.0320\n",
      "Long Trades: 1507 (761 won), Short Trades: 3631 (1777 won), won %: 0.493966523939276, profit: -31000 (gross gain: 1269000, gross loss: -1300000)\n",
      "Evaluating: \n",
      "Long Trades: 0 (0 won), Short Trades: 1127 (538 won), won %: 0.47737355811889975, profit: -25000 (gross gain: 269000, gross loss: -294000)\n",
      "Current epsilon: 0.24774890176799128\n",
      "\n",
      "Training (2):\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6131\n",
      "Long Trades: 695 (356 won), Short Trades: 4228 (2049 won), won %: 0.488523258175909, profit: -56500 (gross gain: 1202500, gross loss: -1259000)\n",
      "Evaluating: \n",
      "Long Trades: 214 (100 won), Short Trades: 946 (454 won), won %: 0.47758620689655173, profit: -26000 (gross gain: 277000, gross loss: -303000)\n",
      "Current epsilon: 0.04439131301369264\n",
      "\n",
      "Training (3):\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.7736\n",
      "Long Trades: 2342 (1158 won), Short Trades: 3005 (1431 won), won %: 0.4841967458387881, profit: -84500 (gross gain: 1294500, gross loss: -1379000)\n",
      "Evaluating: \n",
      "Long Trades: 1004 (496 won), Short Trades: 150 (65 won), won %: 0.4861351819757366, profit: -15500 (gross gain: 280500, gross loss: -296000)\n",
      "Current epsilon: 0.014444757160827857\n",
      "\n",
      "Training (4):\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.6866\n",
      "Long Trades: 3096 (1568 won), Short Trades: 2299 (1126 won), won %: 0.49935125115848006, profit: -3500 (gross gain: 1347000, gross loss: -1350500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.01\n",
      "\n",
      "Training (5):\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.6165\n",
      "Long Trades: 5178 (2600 won), Short Trades: 226 (107 won), won %: 0.5009252405625463, profit: 5000 (gross gain: 1353500, gross loss: -1348500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.01\n",
      "\n",
      "Training (6):\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4964\n",
      "Long Trades: 5150 (2603 won), Short Trades: 242 (122 won), won %: 0.5053783382789317, profit: 29000 (gross gain: 1362500, gross loss: -1333500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.01\n",
      "\n",
      "Training (7):\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.4971\n",
      "Long Trades: 4805 (2408 won), Short Trades: 585 (273 won), won %: 0.4974025974025974, profit: -14000 (gross gain: 1340500, gross loss: -1354500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.01\n",
      "\n",
      "Training (8):\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.3349\n",
      "Long Trades: 5145 (2596 won), Short Trades: 244 (122 won), won %: 0.5043607348302097, profit: 23500 (gross gain: 1359000, gross loss: -1335500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.01\n",
      "\n",
      "Training (9):\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2688\n",
      "Long Trades: 5138 (2596 won), Short Trades: 262 (133 won), won %: 0.5053703703703704, profit: 29000 (gross gain: 1364500, gross loss: -1335500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.01\n",
      "\n",
      "Training (10):\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.2378\n",
      "Long Trades: 5267 (2642 won), Short Trades: 117 (51 won), won %: 0.50018573551263, profit: 1000 (gross gain: 1346500, gross loss: -1345500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.01\n",
      "\n",
      "Training (11):\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1340\n",
      "Long Trades: 5161 (2597 won), Short Trades: 213 (101 won), won %: 0.502046892445106, profit: 11000 (gross gain: 1349000, gross loss: -1338000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.01\n",
      "\n",
      "Training (12):\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1001\n",
      "Long Trades: 4910 (2466 won), Short Trades: 472 (226 won), won %: 0.5001858045336306, profit: 1000 (gross gain: 1346000, gross loss: -1345000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.01\n",
      "\n",
      "Training (13):\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "THRESHOLD = 195\n",
    "MONITOR = True\n",
    "\n",
    "class DQN:\n",
    "\tdef __init__(self, env_string, batch_size=128):\n",
    "\t\tself.env = Environment('EURUSD_H1.csv')\n",
    "\t\tself.memory = deque(maxlen=1000)\n",
    "\t\tself.input_size = self.env.input_size\n",
    "\t\tself.action_size = len(self.env.action_space)\n",
    "\t\tself.batch_size = batch_size\n",
    "\t\tself.gamma = 0.0\n",
    "\t\tself.epsilon = 1.0\n",
    "\t\tself.epsilon_min = 0.01\n",
    "\t\tself.epsilon_decay = 0.9998\n",
    "\t\talpha=0.01\n",
    "\t\talpha_decay=0.01\n",
    "\t\tdropout = 0.3\n",
    "\n",
    "\t\t# Init model\n",
    "\t\tself.model = Sequential()\n",
    "\t\tself.model.add(Dense(24 + 8, input_dim=self.input_size, activation='tanh', kernel_regularizer=l2(0.01), activity_regularizer=l2(0.01)))\n",
    "\t\t# self.model.add(Dropout(dropout))\n",
    "\t\tself.model.add(Dense(32, activation='tanh', kernel_regularizer=l2(0.01), activity_regularizer=l2(0.01)))\n",
    "\t\tself.model.add(Dropout(dropout))\n",
    "\t\tself.model.add(Dense(32, activation='tanh', kernel_regularizer=l2(0.01), activity_regularizer=l2(0.01)))\n",
    "\t\tself.model.add(Dropout(dropout))\n",
    "\t\tself.model.add(Dense(self.action_size, activation='tanh'))\n",
    "\t\tself.model.compile(loss='mse', optimizer=Adam(lr=alpha, decay=alpha_decay))\n",
    "\n",
    "\t\tself.model.summary()\n",
    "\n",
    "\tdef remember(self, state, action, reward, next_state, done):\n",
    "\t\tself.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\tdef replay(self, batch_size):\n",
    "\t\tx_batch, y_batch = [], []\n",
    "\t\tminibatch = random.sample(self.memory, min(len(self.memory), batch_size))\n",
    "\n",
    "\t\tfor state, action, reward, next_state, done in minibatch:\n",
    "\t\t\ty_target = self.model.predict(state) # y_target = [[1, 0, -1]]\n",
    "\t\t\t# print(\"action: {}, reward: {}\".format(action, reward))\n",
    "\t\t\t# print(y_target[0])\n",
    "\t\t\t# print(reward)\n",
    "\t\t\treward = max(min(reward, 1), -1)\n",
    "\t\t\t# print(y_target[0])\n",
    "\t\t\t# print(\"|\")\n",
    "\t\t\ty_target[0][action] = reward if (done or self.gamma == 0) else reward + self.gamma * np.max(self.model.predict(next_state)[0])\n",
    "\t\t\t# print(y_target[0])\n",
    "\t\t\t# print(y_target[0][action])\n",
    "\t\t\t# print(self.model.predict(next_state))\n",
    "\t\t\t# y_target[0][action] = max(min(reward, 1), 0)\n",
    "\t\t\t# print(y_target[0])\n",
    "\t\t\tx_batch.append(state[0])\n",
    "\t\t\ty_batch.append(y_target[0])\n",
    "\n",
    "\t\tself.model.fit(np.array(x_batch), np.array(y_batch), batch_size=len(x_batch), verbose=1)\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tscores = deque(maxlen=100)\n",
    "\t\tavg_scores = []\n",
    "\t\tfor e in range(EPOCHS):\n",
    "\t\t\tprint(\"Training ({}):\".format(e + 1))\n",
    "\n",
    "\t\t\tstate = self.env.reset()\n",
    "\t\t\tstate = self.preprocess_state(state)\n",
    "\t\t\tdone = False\n",
    "\n",
    "\t\t\twhile not done:\n",
    "\t\t\t\taction = self.choose_action(state, self.epsilon)\n",
    "\n",
    "\n",
    "\t\t\t\t# next_index = self.env.next_index\n",
    "\t\t\t\tnext_state, reward, done = self.env.step(action)\n",
    "\n",
    "\t\t\t\t# if action == 1:\n",
    "\t\t\t\t# \tself.env.next_index = next_index\n",
    "\t\t\t\t# \tns, rew, don = self.env.step(2)\n",
    "\t\t\t\t# \tprint(\"1: {} => 2: {}\".format(reward, rew))\n",
    "\t\t\t\t# elif action == 2:\n",
    "\t\t\t\t# \tself.env.next_index = next_index\n",
    "\t\t\t\t# \tns, rew, don = self.env.step(1)\n",
    "\t\t\t\t# \tprint(\"2: {} => 1: {}\".format(reward, rew))\n",
    "\n",
    "\n",
    "\t\t\t\tnext_state = self.preprocess_state(next_state)\n",
    "\t\t\t\tself.remember(state, action, reward, next_state, done)\n",
    "\t\t\t\tstate = next_state\n",
    "\t\t\t\tself.epsilon = max(self.epsilon_min, self.epsilon_decay*self.epsilon)\n",
    "\t\t\t\tif self.env.next_index >= int(len(self.env.dataset) * 0.7): break\n",
    "\n",
    "\t\t\tself.replay(self.batch_size)\n",
    "\t\t\tprint(self.env.report())\n",
    "\n",
    "\t\t\t# test on unoptimized data\n",
    "\t\t\tprint(\"Evaluating: \")\n",
    "\n",
    "\t\t\tstate = self.env.reset()\n",
    "\t\t\tself.env.next_index = int(len(self.env.dataset) * 0.7) + 1\n",
    "\t\t\tstate = self.preprocess_state(state)\n",
    "\t\t\tdone = False\n",
    "\n",
    "\t\t\twhile not done:\n",
    "\t\t\t\taction = self.choose_action(state, -1)\n",
    "\n",
    "\t\t\t\tnext_state, reward, done = self.env.step(action)\n",
    "\t\t\t\tif done: break\n",
    "\n",
    "\t\t\t\tstate = self.preprocess_state(next_state)\n",
    "\t\t\t\tif self.env.next_index >= len(self.env.dataset) - 2: break\n",
    "\n",
    "\t\t\tprint(self.env.report())\n",
    "\t\t\tprint(\"Current epsilon: {}\".format(self.epsilon))\n",
    "\t\t\tprint()\n",
    "\n",
    "\n",
    "\t\tprint('Did not solve after {} episodes :('.format(e))\n",
    "\t\treturn avg_scores\n",
    "\n",
    "\tdef choose_action(self, state, epsilon):\n",
    "\t\t# return random.choice(self.env.action_space)\n",
    "\t\tif np.random.random() <= epsilon:\n",
    "\t\t\treturn random.choice(self.env.action_space)\n",
    "\t\telse:\n",
    "\t\t\treturn np.argmax(self.model(state, training=epsilon>0))\n",
    "\n",
    "\n",
    "\tdef preprocess_state(self, state):\n",
    "\t\treturn np.reshape(state, [1, self.input_size])\n",
    "\n",
    "env_string = 'CartPole-v0'\n",
    "agent = DQN(env_string)\n",
    "scores = agent.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "scores = agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "scores = agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (1):\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.7007\n",
      "Long Trades: 5398 (2719 won), Short Trades: 1 (0 won), won %: 0.5036117799592517, profit: 19500 (gross gain: 1359500, gross loss: -1340000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (2):\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6920\n",
      "Long Trades: 5398 (2719 won), Short Trades: 1 (0 won), won %: 0.5036117799592517, profit: 19500 (gross gain: 1359500, gross loss: -1340000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (3):\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6944\n",
      "Long Trades: 5397 (2719 won), Short Trades: 3 (1 won), won %: 0.5037037037037037, profit: 20000 (gross gain: 1360000, gross loss: -1340000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (4):\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6891\n",
      "Long Trades: 5398 (2719 won), Short Trades: 1 (0 won), won %: 0.5036117799592517, profit: 19500 (gross gain: 1359500, gross loss: -1340000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (5):\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6913\n",
      "Long Trades: 5397 (2719 won), Short Trades: 1 (1 won), won %: 0.50389032975176, profit: 21000 (gross gain: 1360000, gross loss: -1339000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (6):\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6927\n",
      "Long Trades: 5398 (2720 won), Short Trades: 1 (1 won), won %: 0.5039822189294314, profit: 21500 (gross gain: 1360500, gross loss: -1339000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (7):\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6884\n",
      "Long Trades: 5397 (2719 won), Short Trades: 2 (0 won), won %: 0.5036117799592517, profit: 19500 (gross gain: 1359500, gross loss: -1340000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (8):\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6930\n",
      "Long Trades: 5395 (2719 won), Short Trades: 1 (1 won), won %: 0.5040770941438102, profit: 22000 (gross gain: 1360000, gross loss: -1338000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (9):\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6855\n",
      "Long Trades: 5396 (2718 won), Short Trades: 1 (0 won), won %: 0.5036131183991106, profit: 19500 (gross gain: 1359000, gross loss: -1339500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (10):\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6870\n",
      "Long Trades: 5397 (2721 won), Short Trades: 2 (2 won), won %: 0.504352657899611, profit: 23500 (gross gain: 1361500, gross loss: -1338000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (11):\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6815\n",
      "Long Trades: 5397 (2719 won), Short Trades: 2 (1 won), won %: 0.5037969994443415, profit: 20500 (gross gain: 1360000, gross loss: -1339500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (12):\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6862\n",
      "Long Trades: 5396 (2719 won), Short Trades: 3 (2 won), won %: 0.5039822189294314, profit: 21500 (gross gain: 1360500, gross loss: -1339000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (13):\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6882\n",
      "Long Trades: 5397 (2719 won), Short Trades: 0 (0 won), won %: 0.5037984065221419, profit: 20500 (gross gain: 1359500, gross loss: -1339000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (14):\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6846\n",
      "Long Trades: 5399 (2720 won), Short Trades: 0 (0 won), won %: 0.5037969994443415, profit: 20500 (gross gain: 1360000, gross loss: -1339500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (15):\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6832\n",
      "Long Trades: 5398 (2721 won), Short Trades: 1 (1 won), won %: 0.5041674384145212, profit: 22500 (gross gain: 1361000, gross loss: -1338500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (16):\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6865\n",
      "Long Trades: 5398 (2719 won), Short Trades: 1 (0 won), won %: 0.5036117799592517, profit: 19500 (gross gain: 1359500, gross loss: -1340000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (17):\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.6843\n",
      "Long Trades: 5397 (2719 won), Short Trades: 2 (1 won), won %: 0.5037969994443415, profit: 20500 (gross gain: 1360000, gross loss: -1339500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (18):\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6800\n",
      "Long Trades: 5392 (2717 won), Short Trades: 3 (1 won), won %: 0.5037998146431881, profit: 20500 (gross gain: 1359000, gross loss: -1338500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (19):\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6840\n",
      "Long Trades: 5397 (2720 won), Short Trades: 2 (2 won), won %: 0.5041674384145212, profit: 22500 (gross gain: 1361000, gross loss: -1338500)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (20):\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6851\n",
      "Long Trades: 5396 (2719 won), Short Trades: 3 (2 won), won %: 0.5039822189294314, profit: 21500 (gross gain: 1360500, gross loss: -1339000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (21):\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.6819\n",
      "Long Trades: 5398 (2720 won), Short Trades: 1 (1 won), won %: 0.5039822189294314, profit: 21500 (gross gain: 1360500, gross loss: -1339000)\n",
      "Evaluating: \n",
      "Long Trades: 1156 (580 won), Short Trades: 0 (0 won), won %: 0.5017301038062284, profit: 2500 (gross gain: 290000, gross loss: -287500)\n",
      "Current epsilon: 0.001\n",
      "\n",
      "Training (22):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-2914f484acc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-fbaec9a080c0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-fbaec9a080c0>\u001b[0m in \u001b[0;36mchoose_action\u001b[1;34m(self, state, epsilon)\u001b[0m\n\u001b[0;32m    117\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    370\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \"\"\"\n\u001b[1;32m--> 385\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    386\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    214\u001b[0m           rate=self.rate)\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     output = tf_utils.smart_cond(training,\n\u001b[0m\u001b[0;32m    217\u001b[0m                                  \u001b[0mdropped_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                                  lambda: array_ops.identity(inputs))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     62\u001b[0m     return control_flow_ops.cond(\n\u001b[0;32m     63\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m---> 64\u001b[1;33m   return smart_module.smart_cond(\n\u001b[0m\u001b[0;32m     65\u001b[0m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[1;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mdropped_inputs\u001b[1;34m()\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdropped_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m       return nn.dropout(\n\u001b[0m\u001b[0;32m    211\u001b[0m           \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m           \u001b[0mnoise_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_noise_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(x, keep_prob, noise_shape, seed, name, rate)\u001b[0m\n\u001b[0;32m   4939\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You must provide a rate to dropout.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4941\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mdropout_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4942\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mdropout_v2\u001b[1;34m(x, rate, noise_shape, seed, name)\u001b[0m\n\u001b[0;32m   5032\u001b[0m         \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5033\u001b[0m         \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5034\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5035\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5036\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rate is neither scalar nor scalar tensor %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6159\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6160\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6161\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6162\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6163\u001b[0m         x, y)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "scores = agent.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = agent.env.reset()\n",
    "agent.env.next_index = 0\n",
    "state = agent.preprocess_state(state)\n",
    "done = False\n",
    "long, short, pas = 0, 0 ,0\n",
    "actions = []\n",
    "\n",
    "while not done:\n",
    "\taction = agent.choose_action(state, -1)\n",
    "\tnext_state, reward, done = agent.env.step(action)\n",
    "\tif done: break\n",
    "\tstate = agent.preprocess_state(next_state)\n",
    "\tif action == 1:\n",
    "\t\tlong += 1\n",
    "\telif action == 0:\n",
    "\t\tpas += 1\n",
    "\telse:\n",
    "\t\tshort += 1   \n",
    "\tactions.append(action)\n",
    "\tif agent.env.next_index >= len(agent.env.dataset) -1: break\n",
    "\n",
    "print(agent.env.report())\n",
    "print(\"pas: \", pas)\n",
    "print(\"short: \", short)\n",
    "print(\"long: \", long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
